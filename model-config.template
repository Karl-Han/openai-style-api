[
    {
        "token": "f2b7295fc440db7f",
        "type": "azure",
        "config": {
            "api_base": "https://xxxx.openai.azure.com/",
            "deployment_id": "gpt-35-turbo",
            "api_version": "2023-05-15",
            "api_key": "xxxxxx",
            "temperature": 0.8
        }
    },
    {
        "token": "GxqT3BlbkFJj",
        "type": "openai",
        "config": {
            "api_base": "https://api.openai.com/v1/",
            "api_key": "sk-xxxxxx",
            "model": "gpt-3.5-turbo"
        }
    },
    {
        "token": "sb-ede1529390cc",
        "type": "proxy",
        "config": {
            "api_base": "https://api.openai-sb.com/v1/",
            "api_key": "sb-xxxxxx",
            "model": "gpt-3.5-turbo"
        }
    },
    {
        "token": "c115c8f5082",
        "type": "claude-web",
        "config": {
            "cookie": "xxxxxx",
            "proxies": {
                "https": "http://localhost:7890"
            },
            "conversation_id": "xxxxxx",
            "prompt": "The information in [] is the context of the conversation. Please ignore the JSON format of the context during the conversation and answer the user's latest conversation: {newMessage} \n {history}",
            "single_conversation": true
        }
    },
    {
        "token": "7c7aa4a3549f5",
        "type": "zhipu-api",
        "config": {
            "api_key": "xxxxxx",
            "model": "chatglm_lite",
            "temperature": 0.8,
            "top_p": 0.7
        }
    }
]